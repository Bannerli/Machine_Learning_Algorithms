{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autograd functionally\n",
    "import autograd.numpy as np\n",
    "from autograd.misc.flatten import flatten_func\n",
    "from autograd import grad as compute_grad\n",
    "\n",
    "# import various other libraries\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is needed to compensate for %matplotl+ib notebook's tendancy lotted inline\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent function\n",
    "def gradient_descent(g, w ,alpha, max_its, beta):\n",
    "    # flatten the input function, create gradient based on flat function\n",
    "    g_flat, unflatten, w = flatten_func(g, w)\n",
    "    grad = compute_grad(g_flat)\n",
    "\n",
    "    # record history\n",
    "    w_hist = []\n",
    "    # push the first w\n",
    "    w_hist.append(unflatten(w))\n",
    "\n",
    "    # start gradient descent loop\n",
    "    z = np.zeros(np.shape(w))  # momentum term\n",
    "\n",
    "    # over the line\n",
    "    for k in range(max_its):\n",
    "        # plug in value into func and derivative\n",
    "        grad_eval = grad(w)\n",
    "        grad_eval.shape = np.shape(w)\n",
    "\n",
    "        # take descent step with momentum\n",
    "        z = beta * z + grad_eval\n",
    "        w = w -alpha * z\n",
    "\n",
    "        # record weight update\n",
    "        w_hist.append(unflatten(w))\n",
    "\n",
    "    return w_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(cost_hist, ylabelName, label):\n",
    "    figure, axes = plt.subplots(1,1, figsize = (6,5))\n",
    "    axes.plot(range(len(cost_hist)),cost_hist, label = label, linestyle = \"solid\")\n",
    "    axes.set_xlabel(\"iterations\")\n",
    "    axes.set_ylabel(ylabelName)\n",
    "    axes.legend()\n",
    "    plt.show()\n",
    "\n",
    "def model(x ,w):\n",
    "    # feature transformations\n",
    "    f = w[0] + np.dot(x, w[1:])\n",
    "    return f\n",
    "\n",
    "def statistics_number(y, alpha = 1):\n",
    "    negative = np.array(y == -1, dtype = np.int)\n",
    "    positive = np.array(y == 1,dtype = np.int)\n",
    "    nega_number = np.sum(negative)\n",
    "    posi_number = np.sum(positive)\n",
    "    if nega_number < posi_number:\n",
    "        nega_coefficient = negative * alpha\n",
    "        posi_coefficient = positive * 1.0\n",
    "    else:\n",
    "        nega_coefficient = negative * 1.0\n",
    "        posi_coefficient = positive * alpha      \n",
    "    coefficient = nega_coefficient + posi_coefficient \n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvname = 'imbalanced_2class.csv'\n",
    "data = np.loadtxt(csvname, delimiter = ',')\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = statistics_number(y,alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    a_1 = np.array(x>=0, dtype = np.int)\n",
    "    a_2 = np.array(x<0, dtype = np.int)\n",
    "    return a_1*1 + a_2*(-1)\n",
    "\n",
    "def softmax_cost(w):\n",
    "    cost = np.sum(beta*np.log(1+np.exp(-y*model(x,w))))\n",
    "    return cost/float(np.size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "alpha = 0.2\n",
    "max_its = 500\n",
    "gamma = 0\n",
    "w_init = np.random.randn(x.shape[1]+1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = statistics_number(y,alpha = 1)\n",
    "# run gradient descent, create cost function history\n",
    "weight_history = gradient_descent(softmax_cost, w_init, alpha, max_its,beta = gamma)\n",
    "# use MSE to validate the regression quality\n",
    "cost_history = [softmax_cost(v) for v in weight_history]\n",
    "best_w = weight_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w):\n",
    "    y_pred = sign(model(x,w))\n",
    "    y_pred = [y_pred[i][0] for i in range(np.size(y_pred))]\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    A_positive = tp/(tp+fn)\n",
    "    A_negative = tn/(tn+fp)\n",
    "    balanced_A = 0.5*(A_positive+A_negative)\n",
    "    accuracy = (tn+tp)/(tn + fp + fn + tp)\n",
    "    return accuracy, balanced_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9 balanced_accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy_1, balanced_accuracy = accuracy(best_w)\n",
    "print(\"accuracy: \",accuracy_1, \"balanced_accuracy: \",balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = statistics_number(y,alpha = 5)\n",
    "# run gradient descent, create cost function history\n",
    "weight_history = gradient_descent(softmax_cost, w_init, alpha, max_its,beta = gamma)\n",
    "# use MSE to validate the regression quality\n",
    "cost_history = [softmax_cost(v) for v in weight_history]\n",
    "best_w = weight_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  1.0 balanced_accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_2, balanced_accuracy = accuracy(best_w)\n",
    "print(\"accuracy: \",accuracy_2, \"balanced_accuracy: \",balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
